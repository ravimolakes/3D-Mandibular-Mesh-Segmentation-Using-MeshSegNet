{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2072860-569c-4f8c-aecb-94b21aacad82",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (1446633134.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[65], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    C:\\Users\\ravimolake\\Downloads\\mesh mandibular segmentator\\torch-points3d\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "C:\\Users\\ravimolake\\Downloads\\mesh mandibular segmentator\\torch-points3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c52aa-a21a-4186-b77d-68da336d869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/nicolas-chaulet/torch-points3d.git\n",
    "%cd torch-points3d\n",
    "!git checkout 0d83ce22b9245b79b5984c0415f2ae4cb31c24cf  # ✅ Known working commit\n",
    "!pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee8950b9-c9a4-4af1-941d-4c0c34b33a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/ravimolake/Downloads/mesh%20mandibular%20segmentator/torch-points3d/torch-points3d\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Project file:///C:/Users/ravimolake/Downloads/mesh%20mandibular%20segmentator/torch-points3d/torch-points3d has a 'pyproject.toml' and its build backend is missing the 'build_editable' hook. Since it does not have a 'setup.py' nor a 'setup.cfg', it cannot be installed in editable mode. Consider using a build backend that supports PEP 660.\n"
     ]
    }
   ],
   "source": [
    "!pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61aac728-75ea-43b5-aa87-a956f40e5525",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_points3d.applications.semseg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_points3d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msemseg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SemSegModel\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ torch-points3d is installed correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch_points3d.applications.semseg'"
     ]
    }
   ],
   "source": [
    "from torch_points3d.applications.semseg import SemSegModel\n",
    "print(\"✅ torch-points3d is installed correctly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ca6af2d-dbe2-4235-a00f-225d7f2aab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping torchaudio as it is not installed.\n",
      "WARNING: Skipping torch-points3d as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.2.0+cpu\n",
      "Uninstalling torch-2.2.0+cpu:\n",
      "  Successfully uninstalled torch-2.2.0+cpu\n",
      "Found existing installation: torch_scatter 2.1.2+pt22cpu\n",
      "Uninstalling torch_scatter-2.1.2+pt22cpu:\n",
      "  Successfully uninstalled torch_scatter-2.1.2+pt22cpu\n",
      "Found existing installation: torch_sparse 0.6.18+pt22cpu\n",
      "Uninstalling torch_sparse-0.6.18+pt22cpu:\n",
      "  Successfully uninstalled torch_sparse-0.6.18+pt22cpu\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==2.2.0+cpu\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torch-2.2.0%2Bcpu-cp312-cp312-win_amd64.whl (200.7 MB)\n",
      "Requirement already satisfied: torchvision==0.17.0+cpu in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (0.17.0+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torch==2.2.0+cpu) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torch==2.2.0+cpu) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torch==2.2.0+cpu) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torch==2.2.0+cpu) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torch==2.2.0+cpu) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torch==2.2.0+cpu) (2024.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torchvision==0.17.0+cpu) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torchvision==0.17.0+cpu) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torchvision==0.17.0+cpu) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from jinja2->torch==2.2.0+cpu) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from requests->torchvision==0.17.0+cpu) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from requests->torchvision==0.17.0+cpu) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from requests->torchvision==0.17.0+cpu) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from requests->torchvision==0.17.0+cpu) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from sympy->torch==2.2.0+cpu) (1.3.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.2.0+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "monai 1.5.0 requires torch<2.7.0,>=2.4.1, but you have torch 2.2.0+cpu which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchaudio torch-points3d torch-scatter torch-sparse -y\n",
    "!pip install torch==2.2.0+cpu torchvision==0.17.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da419f55-363d-4449-96aa-f367ad76dcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cpu.html\n",
      "Collecting torch-scatter\n",
      "  Using cached https://data.pyg.org/whl/torch-2.2.0%2Bcpu/torch_scatter-2.1.2%2Bpt22cpu-cp312-cp312-win_amd64.whl (336 kB)\n",
      "Installing collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.1.2+pt22cpu\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.2.0+cpu.html\n",
      "Collecting torch-sparse\n",
      "  Using cached https://data.pyg.org/whl/torch-2.2.0%2Bcpu/torch_sparse-0.6.18%2Bpt22cpu-cp312-cp312-win_amd64.whl (789 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torch-sparse) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from scipy->torch-sparse) (1.26.4)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.18+pt22cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.0+cpu.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.2.0+cpu.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a70e90f3-91e3-4e03-b621-3156b4b4ec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/nicolas-chaulet/torch-points3d.git\n",
      "  Cloning https://github.com/nicolas-chaulet/torch-points3d.git to c:\\users\\ravimolake\\appdata\\local\\temp\\pip-req-build-w6o28zfz\n",
      "  Resolved https://github.com/nicolas-chaulet/torch-points3d.git to commit 8e4c19ecb81926626231bf185e9eca77d92a0606\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting gdown<4.0.0,>=3.12.0 (from torch_points3d==0.2.0)\n",
      "  Using cached gdown-3.15.0.tar.gz (10 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: h5py<4.0.0,>=3.3.0 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torch_points3d==0.2.0) (3.11.0)\n",
      "Collecting hydra-core<1.1.0,>=1.0.0 (from torch_points3d==0.2.0)\n",
      "  Using cached hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting laspy<3.0.0,>=2.0.3 (from torch_points3d==0.2.0)\n",
      "  Using cached laspy-2.5.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: matplotlib<4.0,>=3.1 in c:\\users\\ravimolake\\anaconda3\\lib\\site-packages (from torch_points3d==0.2.0) (3.9.2)\n",
      "Collecting numba<0.51.0,>=0.50.0 (from torch_points3d==0.2.0)\n",
      "  Using cached numba-0.50.1.tar.gz (2.0 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting numpy<1.20.0 (from torch_points3d==0.2.0)\n",
      "  Using cached numpy-1.19.5.zip (7.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/nicolas-chaulet/torch-points3d.git 'C:\\Users\\ravimolake\\AppData\\Local\\Temp\\pip-req-build-w6o28zfz'\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 379, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 95, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 427, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 230, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 156, in __bool__\n",
      "    return bool(self._sequence)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 174, in __bool__\n",
      "    return any(self)\n",
      "           ^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 162, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 53, in _iter_built\n",
      "    candidate = func()\n",
      "                ^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 186, in _make_candidate_from_link\n",
      "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 232, in _make_base_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "                                       ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 303, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 158, in __init__\n",
      "    self.dist = self._prepare()\n",
      "                ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 235, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 314, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 527, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 642, in _prepare_linked_requirement\n",
      "    dist = _get_prepared_distribution(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 72, in _get_prepared_distribution\n",
      "    abstract_dist.prepare_distribution_metadata(\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 56, in prepare_distribution_metadata\n",
      "    self._install_build_reqs(finder)\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 126, in _install_build_reqs\n",
      "    build_reqs = self._get_build_requires_wheel()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 103, in _get_build_requires_wheel\n",
      "    return backend.get_requires_for_build_wheel()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 706, in get_requires_for_build_wheel\n",
      "    return super().get_requires_for_build_wheel(config_settings=cs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py\", line 166, in get_requires_for_build_wheel\n",
      "    return self._call_hook('get_requires_for_build_wheel', {\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py\", line 321, in _call_hook\n",
      "    raise BackendUnavailable(data.get('traceback', ''))\n",
      "pip._vendor.pyproject_hooks._impl.BackendUnavailable: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n",
      "    obj = import_module(mod_path)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ravimolake\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\ravimolake\\AppData\\Local\\Temp\\pip-build-env-3jlysf1j\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 18, in <module>\n",
      "    from setuptools.extern.six import PY3, string_types\n",
      "ModuleNotFoundError: No module named 'setuptools.extern.six'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/nicolas-chaulet/torch-points3d.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aa3d351-27c6-46be-beaa-15173814c1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools==59.5.0\n",
      "  Using cached setuptools-59.5.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.44.0\n",
      "    Uninstalling wheel-0.44.0:\n",
      "      Successfully uninstalled wheel-0.44.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 59.5.0\n",
      "    Uninstalling setuptools-59.5.0:\n",
      "      Successfully uninstalled setuptools-59.5.0\n",
      "Successfully installed setuptools-59.5.0 wheel-0.45.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda 24.9.2 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install setuptools==59.5.0 wheel --upgrade --force-reinstall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fb1e314-9484-4a64-8b44-c5c14f9b338d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/nicolas-chaulet/torch-points3d.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d48cd090-7039-41e1-a11d-3c93a0041e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'torch-points3d'...\n",
      "Updating files:  33% (192/568)\n",
      "Updating files:  34% (194/568)\n",
      "Updating files:  35% (199/568)\n",
      "Updating files:  36% (205/568)\n",
      "Updating files:  37% (211/568)\n",
      "Updating files:  38% (216/568)\n",
      "Updating files:  39% (222/568)\n",
      "Updating files:  40% (228/568)\n",
      "Updating files:  41% (233/568)\n",
      "Updating files:  42% (239/568)\n",
      "Updating files:  42% (240/568)\n",
      "Updating files:  42% (242/568)\n",
      "Updating files:  42% (243/568)\n",
      "Updating files:  42% (244/568)\n",
      "Updating files:  43% (245/568)\n",
      "Updating files:  43% (246/568)\n",
      "Updating files:  44% (250/568)\n",
      "Updating files:  45% (256/568)\n",
      "Updating files:  45% (259/568)\n",
      "Updating files:  46% (262/568)\n",
      "Updating files:  47% (267/568)\n",
      "Updating files:  47% (269/568)\n",
      "Updating files:  48% (273/568)\n",
      "Updating files:  49% (279/568)\n",
      "Updating files:  50% (284/568)\n",
      "Updating files:  51% (290/568)\n",
      "Updating files:  52% (296/568)\n",
      "Updating files:  53% (302/568)\n",
      "Updating files:  54% (307/568)\n",
      "Updating files:  55% (313/568)\n",
      "Updating files:  56% (319/568)\n",
      "Updating files:  57% (324/568)\n",
      "Updating files:  58% (330/568)\n",
      "Updating files:  59% (336/568)\n",
      "Updating files:  60% (341/568)\n",
      "Updating files:  61% (347/568)\n",
      "Updating files:  62% (353/568)\n",
      "Updating files:  63% (358/568)\n",
      "Updating files:  64% (364/568)\n",
      "Updating files:  65% (370/568)\n",
      "Updating files:  66% (375/568)\n",
      "Updating files:  67% (381/568)\n",
      "Updating files:  68% (387/568)\n",
      "Updating files:  69% (392/568)\n",
      "Updating files:  70% (398/568)\n",
      "Updating files:  71% (404/568)\n",
      "Updating files:  72% (409/568)\n",
      "Updating files:  73% (415/568)\n",
      "Updating files:  74% (421/568)\n",
      "Updating files:  75% (426/568)\n",
      "Updating files:  76% (432/568)\n",
      "Updating files:  77% (438/568)\n",
      "Updating files:  78% (444/568)\n",
      "Updating files:  79% (449/568)\n",
      "Updating files:  80% (455/568)\n",
      "Updating files:  81% (461/568)\n",
      "Updating files:  82% (466/568)\n",
      "Updating files:  83% (472/568)\n",
      "Updating files:  84% (478/568)\n",
      "Updating files:  85% (483/568)\n",
      "Updating files:  86% (489/568)\n",
      "Updating files:  87% (495/568)\n",
      "Updating files:  88% (500/568)\n",
      "Updating files:  89% (506/568)\n",
      "Updating files:  90% (512/568)\n",
      "Updating files:  91% (517/568)\n",
      "Updating files:  92% (523/568)\n",
      "Updating files:  93% (529/568)\n",
      "Updating files:  94% (534/568)\n",
      "Updating files:  95% (540/568)\n",
      "Updating files:  96% (546/568)\n",
      "Updating files:  97% (551/568)\n",
      "Updating files:  98% (557/568)\n",
      "Updating files:  99% (563/568)\n",
      "Updating files: 100% (568/568)\n",
      "Updating files: 100% (568/568), done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/ravimolake/Downloads/mesh%20mandibular%20segmentator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: file:///C:/Users/ravimolake/Downloads/mesh%20mandibular%20segmentator does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/nicolas-chaulet/torch-points3d.git\n",
    "!cd torch-points3d\n",
    "!pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa5e5cf7-508c-4741-b685-2bd096778b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravimolake\\Downloads\\mesh mandibular segmentator\\torch-points3d\n"
     ]
    }
   ],
   "source": [
    "cd torch-points3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9c2c8ff-b66a-4914-91a6-773528c757c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/ravimolake/Downloads/mesh%20mandibular%20segmentator/torch-points3d\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Project file:///C:/Users/ravimolake/Downloads/mesh%20mandibular%20segmentator/torch-points3d has a 'pyproject.toml' and its build backend is missing the 'build_editable' hook. Since it does not have a 'setup.py' nor a 'setup.cfg', it cannot be installed in editable mode. Consider using a build backend that supports PEP 660.\n"
     ]
    }
   ],
   "source": [
    "!pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534ccce1-8821-4317-8305-ad17e3793f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\paramiko\\pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\ravimolake\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:243: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_points3d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, f1_score\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmonai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiceLoss, FocalLoss\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_points3d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msemseg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SemSegModel\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# --------------------------------------------\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Step 1: Convert Mesh to Point Cloud\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# --------------------------------------------\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch_points3d'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from monai.losses import DiceLoss, FocalLoss\n",
    "from torch_points3d.applications.semseg import SemSegModel\n",
    "import joblib\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 1: Convert Mesh to Point Cloud\n",
    "# --------------------------------------------\n",
    "COLOR_TO_CLASS = {\n",
    "    (250, 250, 0): 1,   # Lower Teeth\n",
    "    (255, 0, 0): 2,     # Left Canal\n",
    "    (0, 0, 255): 3      # Right Canal\n",
    "}\n",
    "\n",
    "def closest_color_class(rgb):\n",
    "    min_dist = float('inf')\n",
    "    class_id = 0\n",
    "    for known_rgb, cid in COLOR_TO_CLASS.items():\n",
    "        dist = np.linalg.norm(np.array(rgb) - np.array(known_rgb))\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            class_id = cid\n",
    "    return class_id\n",
    "\n",
    "def convert_meshes_to_pointclouds(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    files = [f for f in os.listdir(input_dir) if f.endswith(\".ply\")]\n",
    "    for fname in tqdm(files, desc=\"Converting to Point Clouds\"):\n",
    "        mesh_path = os.path.join(input_dir, fname)\n",
    "        mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "        mesh.compute_vertex_normals()\n",
    "\n",
    "        pcd = mesh.sample_points_uniformly(number_of_points=10000)\n",
    "        colors = np.asarray(pcd.colors) * 255\n",
    "        colors = np.round(colors).astype(int)\n",
    "        labels = np.array([closest_color_class(rgb) for rgb in colors])\n",
    "\n",
    "        np.savez(\n",
    "            os.path.join(output_dir, fname.replace(\".ply\", \".npz\")),\n",
    "            pos=np.asarray(pcd.points).astype(np.float32),\n",
    "            y=labels.astype(np.int64)\n",
    "        )\n",
    "\n",
    "# Run conversion\n",
    "convert_meshes_to_pointclouds(\n",
    "    input_dir=\"DentalSegDataset/labelTr\",\n",
    "    output_dir=\"pointclouds\"\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 2: Dataset and Dataloader with Caching\n",
    "# --------------------------------------------\n",
    "\n",
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        self.files = file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.files[idx])\n",
    "        pos = torch.tensor(data['pos'], dtype=torch.float32)\n",
    "        y = torch.tensor(data['y'], dtype=torch.long) - 1  # [1,2,3] -> [0,1,2]\n",
    "        return {\"pos\": pos, \"y\": y}\n",
    "\n",
    "def load_pointcloud_dataset(folder=\"pointclouds\", cache_path=\"pointnet2_dataset_cache.pkl\", force_reload=False):\n",
    "    if not force_reload and os.path.exists(cache_path):\n",
    "        print(\"🔄 Loading PointNet++ dataset from cache...\")\n",
    "        return joblib.load(cache_path)\n",
    "    else:\n",
    "        print(\"📥 Processing .npz point clouds from folder...\")\n",
    "        files = sorted([os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(\".npz\")])\n",
    "        joblib.dump(files, cache_path)\n",
    "        print(\"✅ PointNet++ Dataset cache saved.\")\n",
    "        return files\n",
    "        \n",
    "if os.path.exists(\"pointnet2_dataset_cache.pkl\"):\n",
    "    os.remove(\"pointnet2_dataset_cache.pkl\")  # ✅ delete broken/empty cache file\n",
    "    print(\"deleted file\")\n",
    "\n",
    "# Load cached or generate file list\n",
    "files = load_pointcloud_dataset(\"pointclouds\", \"pointnet2_dataset_cache.pkl\", force_reload=False)\n",
    "\n",
    "# Train-val split and dataloaders\n",
    "train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(PointCloudDataset(train_files), batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(PointCloudDataset(val_files), batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250013c-09f4-469d-8337-70e1121572ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from monai.losses import DiceLoss, FocalLoss\n",
    "\n",
    "# -----------------------------\n",
    "# 🧠 Model Setup\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SemSegModel.load_from_config(\"pointnet2_dental.yaml\").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -----------------------------\n",
    "# ⚖️ Weighted Dice + Focal Loss\n",
    "# -----------------------------\n",
    "dice_loss = DiceLoss(\n",
    "    to_onehot_y=True,\n",
    "    softmax=True,\n",
    "    include_background=True,\n",
    "    weight=torch.tensor([1.0, 4.0, 4.0]).to(device)\n",
    ")\n",
    "\n",
    "focal_loss = FocalLoss(\n",
    "    to_onehot_y=True,\n",
    "    weight=torch.tensor([1.0, 4.0, 4.0]).to(device)\n",
    ")\n",
    "\n",
    "def loss_fn(pred, target):\n",
    "    return 0.5 * dice_loss(pred, target) + 0.5 * focal_loss(pred, target)\n",
    "\n",
    "# -----------------------------\n",
    "# 📊 Metric Tracking Initialization\n",
    "# -----------------------------\n",
    "total_losses = []\n",
    "dice_scores_class1 = []\n",
    "dice_scores_class2 = []\n",
    "dice_scores_class3 = []\n",
    "avg_dice_scores = []\n",
    "overall_accuracies = []\n",
    "\n",
    "best_dice = 0.0\n",
    "\n",
    "# -----------------------------\n",
    "# 🏋️‍♂️ Training Loop\n",
    "# -----------------------------\n",
    "for epoch in range(1, 21):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_iter = tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False)\n",
    "\n",
    "    for batch in train_iter:\n",
    "        inputs = batch.pos.to(device)           # [N, 3]\n",
    "        labels = batch.y.to(device).long()      # [N]\n",
    "\n",
    "        outputs = model(batch).to(device)       # [N, 3]\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        train_iter.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"\\n📉 Epoch {epoch} | Total Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 📊 Validation\n",
    "    # -----------------------------\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = batch.pos.to(device)\n",
    "            labels = batch.y.to(device).long()\n",
    "\n",
    "            outputs = model(batch)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 🔁 Remap [0,1,2] → [1,2,3] for reporting\n",
    "    all_preds = [p + 1 for p in all_preds]\n",
    "    all_labels = [l + 1 for l in all_labels]\n",
    "\n",
    "    print(\"\\n📊 Validation Report:\")\n",
    "    print(classification_report(\n",
    "        all_labels,\n",
    "        all_preds,\n",
    "        labels=[1, 2, 3],\n",
    "        target_names=[\"Teeth\", \"Left Canal\", \"Right Canal\"],\n",
    "        zero_division=0\n",
    "    ))\n",
    "\n",
    "    print(\"🎯 Dice per class:\")\n",
    "    dice_scores = []\n",
    "    for cls in [1, 2, 3]:\n",
    "        cls_dice = f1_score(\n",
    "            np.array(all_labels) == cls,\n",
    "            np.array(all_preds) == cls\n",
    "        )\n",
    "        dice_scores.append(cls_dice)\n",
    "        print(f\"Class {cls} Dice: {cls_dice:.3f}\")\n",
    "\n",
    "    class_1_dice = dice_scores[0]\n",
    "    class_2_dice = dice_scores[1]\n",
    "    class_3_dice = dice_scores[2]\n",
    "    avg_dice = np.mean(dice_scores)\n",
    "\n",
    "    # ✅ Save best model\n",
    "    if avg_dice > best_dice:\n",
    "        best_dice = avg_dice\n",
    "        torch.save(model.state_dict(), \"best_pointnet2_model.pth\")\n",
    "        print(f\"💾 Best model saved with Avg Dice: {avg_dice:.4f}\")\n",
    "\n",
    "    # ✅ Accuracy\n",
    "    overall_acc = np.mean(np.array(all_preds) == np.array(all_labels)) * 100\n",
    "    print(f\"✅ Overall Accuracy: {overall_acc:.2f}%\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 📌 Save Metrics for Graphs\n",
    "    # -----------------------------\n",
    "    total_losses.append(total_loss)\n",
    "    dice_scores_class1.append(class_1_dice)\n",
    "    dice_scores_class2.append(class_2_dice)\n",
    "    dice_scores_class3.append(class_3_dice)\n",
    "    avg_dice_scores.append(avg_dice)\n",
    "    overall_accuracies.append(overall_acc)\n",
    "\n",
    "# -----------------------------\n",
    "# ✅ Final Summary After Training\n",
    "# -----------------------------\n",
    "best_epoch = np.argmax(avg_dice_scores)\n",
    "print(\"\\n📈 Training Complete!\")\n",
    "print(f\"🏆 Best Model at Epoch {best_epoch + 1}\")\n",
    "print(f\"   • Total Loss      : {total_losses[best_epoch]:.4f}\")\n",
    "print(f\"   • Dice - Teeth    : {dice_scores_class1[best_epoch]:.4f}\")\n",
    "print(f\"   • Dice - Left Canal : {dice_scores_class2[best_epoch]:.4f}\")\n",
    "print(f\"   • Dice - Right Canal: {dice_scores_class3[best_epoch]:.4f}\")\n",
    "print(f\"   • Avg Dice        : {avg_dice_scores[best_epoch]:.4f}\")\n",
    "print(f\"   • Accuracy        : {overall_accuracies[best_epoch]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59f214-5a84-439f-8f65-0a07e4ea04b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_points3d.applications.semseg import SemSegModel\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SemSegModel.load_from_config(\"pointnet2_dental.yaml\")\n",
    "model.load_state_dict(torch.load(\"best_pointnet2_model.pth\"))\n",
    "model.eval().to(device)\n",
    "\n",
    "# Load point cloud\n",
    "data = np.load(\"pointclouds/sample_case_01.npz\")\n",
    "points = torch.tensor(data['pos'], dtype=torch.float32).unsqueeze(0).to(device)  # [1, N, 3]\n",
    "true_labels = data['y'] - 1\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    out = model(pos_dict={\"pos\": points})\n",
    "    preds = out.argmax(dim=1).cpu().numpy()[0]\n",
    "\n",
    "np.save(\"predicted_labels_pointnet.npy\", preds)\n",
    "\n",
    "# Visualize\n",
    "def visualize(points_np, pred_labels, true_labels=None):\n",
    "    label_colors = {0: 'yellow', 1: 'green', 2: 'red'}\n",
    "    pred_colors = [label_colors[int(l)] for l in pred_labels]\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    for i, angle in enumerate([30, 60, 90]):\n",
    "        ax = fig.add_subplot(1, 3, i+1, projection='3d')\n",
    "        ax.scatter(points_np[:, 0], points_np[:, 1], points_np[:, 2], c=pred_colors, s=3)\n",
    "        ax.set_title(f\"Predicted - View {angle}°\")\n",
    "        ax.view_init(elev=10, azim=angle)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    legend = [mpatches.Patch(color='yellow', label='Teeth'),\n",
    "              mpatches.Patch(color='green', label='Left Canal'),\n",
    "              mpatches.Patch(color='red', label='Right Canal')]\n",
    "    plt.legend(handles=legend, loc='upper center', bbox_to_anchor=(0.5, 0.05), ncol=3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if true_labels is not None:\n",
    "        true_colors = [label_colors[int(l)] for l in true_labels]\n",
    "        fig_gt = plt.figure()\n",
    "        ax = fig_gt.add_subplot(111, projection='3d')\n",
    "        ax.scatter(points_np[:, 0], points_np[:, 1], points_np[:, 2], c=true_colors, s=3)\n",
    "        ax.set_title(\"Ground Truth\")\n",
    "        ax.set_axis_off()\n",
    "        plt.show()\n",
    "\n",
    "visualize(points.squeeze(0).cpu().numpy(), preds, true_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dadc21-e285-41ef-9792-d81292b8dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 📁 Save metrics\n",
    "metrics = {\n",
    "    \"losses\": total_losses,\n",
    "    \"dice_teeth\": dice_scores_class1,\n",
    "    \"dice_left\": dice_scores_class2,\n",
    "    \"dice_right\": dice_scores_class3,\n",
    "    \"avg_dice\": avg_dice_scores,\n",
    "    \"accuracy\": overall_accuracies\n",
    "}\n",
    "with open(\"metrics_pointnet.json\", \"w\") as f:\n",
    "    json.dump(metrics, f)  # 🔁 Change filename for each model\n",
    "\n",
    "# 📊 Plot\n",
    "epochs = range(1, len(avg_dice_scores) + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, avg_dice_scores, label='Avg Dice')\n",
    "plt.plot(epochs, overall_accuracies, label='Accuracy')\n",
    "plt.title(\"DGCNN: Dice & Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
